{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shawmica/Student_GradePrediction_Model/blob/main/Model_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrXDRc1W8cZ6",
        "outputId": "b63d0337-6008-4039-db55-ed40369948d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9I4nOzg9g5C",
        "outputId": "ff4d4d31-c810-4ad6-f3eb-ce085a467ec3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (704, 5)\n",
            "Validation shape: (151, 5)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define paths to your Excel files in Google Drive\n",
        "train_path = '/content/drive/My Drive/train_data (34).xlsx'\n",
        "val_path = '/content/drive/My Drive/val_data (31).xlsx'\n",
        "\n",
        "# Load into DataFrames\n",
        "train_df = pd.read_excel(train_path)\n",
        "val_df = pd.read_excel(val_path)\n",
        "\n",
        "# Preview\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(\"Validation shape:\", val_df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlnGmB_5Obcw"
      },
      "source": [
        "features (inputs) and target (output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hy1a8hLQ9uc5"
      },
      "outputs": [],
      "source": [
        "# Define your final selected feature columns and target\n",
        "feature_cols = ['QuizAverage','StudyEfficiency','ParticipationScore','AssignmentPenaltyScore']\n",
        "target_col = 'EncodedGrade'\n",
        "\n",
        "# Split features (X) and target (y)\n",
        "X_train = train_df[feature_cols]\n",
        "y_train = train_df[target_col]\n",
        "\n",
        "X_val = val_df[feature_cols]\n",
        "y_val = val_df[target_col]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "905g3OTVEwGw"
      },
      "outputs": [],
      "source": [
        "#from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# Fit label binarizer on training labels\n",
        "#lb = LabelBinarizer()\n",
        "#y_train_ohe = lb.fit_transform(y_train)\n",
        "#y_val_ohe = lb.transform(y_val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Enki9GNxOx1C"
      },
      "source": [
        "calculates the number of unique classes (labels) in the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trrAU820D4gg"
      },
      "outputs": [],
      "source": [
        "#n_classes = len(y_train.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eobvvPR8DLJA",
        "outputId": "8fd54d7c-d968-44d3-ef2b-e69d942509c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.7.1)\n",
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.12/dist-packages (0.13.0)\n",
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.12/dist-packages (0.10.2)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from scikeras) (3.10.0)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (25.7.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (25.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (0.5.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras>=3.2.0->scikeras) (4.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.2.0->scikeras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.2.0->scikeras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U scikit-learn scikeras scikit-optimize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "km3XNT6yJUwA"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train)#Learns all unique labels from your training target (y_train) and maps them to numbers.\n",
        "y_val_enc = le.transform(y_val)\n",
        "#stores the actual list of unique labels\n",
        "n_classes = len(le.classes_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gjq9U4ejPOAr"
      },
      "source": [
        "customizable neural network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gn7FzSWyDSC6"
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_model(learning_rate=0.001, dropout1=0.2, dropout2=0.1,\n",
        "                neurons1=128, neurons2=64, neurons3=64, neurons4=32,\n",
        "                l2=1e-4):\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization, Activation\n",
        "    from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "    n1 = int(neurons1)\n",
        "    n2 = int(max(neurons2, n1))\n",
        "    n3 = int(max(neurons3, n2))\n",
        "    n4 = int(min(neurons4, n3))\n",
        "\n",
        "    reg = tf.keras.regularizers.l2(l2)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape=(X_train.shape[1],)),\n",
        "\n",
        "        Dense(n1, kernel_regularizer=reg),\n",
        "        BatchNormalization(), Activation('relu'),\n",
        "        Dropout(dropout1),\n",
        "\n",
        "        Dense(n2, kernel_regularizer=reg),\n",
        "        BatchNormalization(), Activation('relu'),\n",
        "        Dropout(dropout2),\n",
        "\n",
        "        Dense(n3, kernel_regularizer=reg),\n",
        "        BatchNormalization(), Activation('relu'),\n",
        "\n",
        "        Dense(n4, kernel_regularizer=reg),\n",
        "        BatchNormalization(), Activation('relu'),\n",
        "\n",
        "        Dense(n_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    opt = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l4ia8PgPWOS"
      },
      "source": [
        "ensures One model training at a time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6if1Kl52DUF3"
      },
      "outputs": [],
      "source": [
        "n_jobs=1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5QR71LNPdF-"
      },
      "source": [
        "Bayesian hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xejcjusKKIRi",
        "outputId": "9b066551-24f4-441b-d8cc-4e7f83bfe9c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END batch_size=31, epochs=98, model__dropout1=0.47314719953913353, model__dropout2=0.2263198373948195, model__learning_rate=0.0010243393225105074, model__neurons1=144, model__neurons2=66, model__neurons3=103, model__neurons4=40; total time=  30.0s\n",
            "[CV] END batch_size=31, epochs=98, model__dropout1=0.47314719953913353, model__dropout2=0.2263198373948195, model__learning_rate=0.0010243393225105074, model__neurons1=144, model__neurons2=66, model__neurons3=103, model__neurons4=40; total time=  17.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c3e8045db20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END batch_size=31, epochs=98, model__dropout1=0.47314719953913353, model__dropout2=0.2263198373948195, model__learning_rate=0.0010243393225105074, model__neurons1=144, model__neurons2=66, model__neurons3=103, model__neurons4=40; total time=  17.8s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c3e80236200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END batch_size=55, epochs=111, model__dropout1=0.22136404395367001, model__dropout2=0.4804895626373318, model__learning_rate=0.0039118639884156686, model__neurons1=76, model__neurons2=45, model__neurons3=66, model__neurons4=67; total time=  17.9s\n",
            "[CV] END batch_size=55, epochs=111, model__dropout1=0.22136404395367001, model__dropout2=0.4804895626373318, model__learning_rate=0.0039118639884156686, model__neurons1=76, model__neurons2=45, model__neurons3=66, model__neurons4=67; total time=  16.9s\n",
            "[CV] END batch_size=55, epochs=111, model__dropout1=0.22136404395367001, model__dropout2=0.4804895626373318, model__learning_rate=0.0039118639884156686, model__neurons1=76, model__neurons2=45, model__neurons3=66, model__neurons4=67; total time=  15.7s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END batch_size=33, epochs=113, model__dropout1=0.14194366342108145, model__dropout2=0.2733331207480901, model__learning_rate=3.663241571989203e-05, model__neurons1=151, model__neurons2=47, model__neurons3=104, model__neurons4=61; total time=  19.7s\n",
            "[CV] END batch_size=33, epochs=113, model__dropout1=0.14194366342108145, model__dropout2=0.2733331207480901, model__learning_rate=3.663241571989203e-05, model__neurons1=151, model__neurons2=47, model__neurons3=104, model__neurons4=61; total time=  22.9s\n",
            "[CV] END batch_size=33, epochs=113, model__dropout1=0.14194366342108145, model__dropout2=0.2733331207480901, model__learning_rate=3.663241571989203e-05, model__neurons1=151, model__neurons2=47, model__neurons3=104, model__neurons4=61; total time=  19.7s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END batch_size=53, epochs=54, model__dropout1=0.33921883100485123, model__dropout2=0.42110591246252427, model__learning_rate=0.0003708147357379244, model__neurons1=82, model__neurons2=105, model__neurons3=116, model__neurons4=89; total time=  11.5s\n",
            "[CV] END batch_size=53, epochs=54, model__dropout1=0.33921883100485123, model__dropout2=0.42110591246252427, model__learning_rate=0.0003708147357379244, model__neurons1=82, model__neurons2=105, model__neurons3=116, model__neurons4=89; total time=  10.9s\n",
            "[CV] END batch_size=53, epochs=54, model__dropout1=0.33921883100485123, model__dropout2=0.42110591246252427, model__learning_rate=0.0003708147357379244, model__neurons1=82, model__neurons2=105, model__neurons3=116, model__neurons4=89; total time=  12.6s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END batch_size=53, epochs=75, model__dropout1=0.31064809485107703, model__dropout2=0.3862853048428132, model__learning_rate=0.005147024286785697, model__neurons1=202, model__neurons2=73, model__neurons3=94, model__neurons4=44; total time=  15.0s\n",
            "[CV] END batch_size=53, epochs=75, model__dropout1=0.31064809485107703, model__dropout2=0.3862853048428132, model__learning_rate=0.005147024286785697, model__neurons1=202, model__neurons2=73, model__neurons3=94, model__neurons4=44; total time=  15.0s\n",
            "[CV] END batch_size=53, epochs=75, model__dropout1=0.31064809485107703, model__dropout2=0.3862853048428132, model__learning_rate=0.005147024286785697, model__neurons1=202, model__neurons2=73, model__neurons3=94, model__neurons4=44; total time=  14.8s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END batch_size=49, epochs=115, model__dropout1=0.1654428714554201, model__dropout2=0.17537011670617209, model__learning_rate=0.0025206334448741735, model__neurons1=136, model__neurons2=76, model__neurons3=83, model__neurons4=79; total time=  18.8s\n",
            "[CV] END batch_size=49, epochs=115, model__dropout1=0.1654428714554201, model__dropout2=0.17537011670617209, model__learning_rate=0.0025206334448741735, model__neurons1=136, model__neurons2=76, model__neurons3=83, model__neurons4=79; total time=  18.9s\n",
            "[CV] END batch_size=49, epochs=115, model__dropout1=0.1654428714554201, model__dropout2=0.17537011670617209, model__learning_rate=0.0025206334448741735, model__neurons1=136, model__neurons2=76, model__neurons3=83, model__neurons4=79; total time=  19.4s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END batch_size=43, epochs=102, model__dropout1=0.2436091727685616, model__dropout2=0.44973011813378316, model__learning_rate=0.0005995964127756074, model__neurons1=178, model__neurons2=94, model__neurons3=73, model__neurons4=75; total time=  19.6s\n",
            "[CV] END batch_size=43, epochs=102, model__dropout1=0.2436091727685616, model__dropout2=0.44973011813378316, model__learning_rate=0.0005995964127756074, model__neurons1=178, model__neurons2=94, model__neurons3=73, model__neurons4=75; total time=  17.4s\n",
            "[CV] END batch_size=43, epochs=102, model__dropout1=0.2436091727685616, model__dropout2=0.44973011813378316, model__learning_rate=0.0005995964127756074, model__neurons1=178, model__neurons2=94, model__neurons3=73, model__neurons4=75; total time=  18.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END batch_size=38, epochs=114, model__dropout1=0.2985866814386867, model__dropout2=0.43506257482421073, model__learning_rate=9.379505596171679e-05, model__neurons1=74, model__neurons2=87, model__neurons3=34, model__neurons4=47; total time=  19.8s\n",
            "[CV] END batch_size=38, epochs=114, model__dropout1=0.2985866814386867, model__dropout2=0.43506257482421073, model__learning_rate=9.379505596171679e-05, model__neurons1=74, model__neurons2=87, model__neurons3=34, model__neurons4=47; total time=  17.9s\n",
            "[CV] END batch_size=38, epochs=114, model__dropout1=0.2985866814386867, model__dropout2=0.43506257482421073, model__learning_rate=9.379505596171679e-05, model__neurons1=74, model__neurons2=87, model__neurons3=34, model__neurons4=47; total time=  22.3s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END batch_size=62, epochs=96, model__dropout1=0.44866077138528604, model__dropout2=0.26632843503178144, model__learning_rate=0.0001390574606467376, model__neurons1=105, model__neurons2=32, model__neurons3=68, model__neurons4=64; total time=  15.4s\n",
            "[CV] END batch_size=62, epochs=96, model__dropout1=0.44866077138528604, model__dropout2=0.26632843503178144, model__learning_rate=0.0001390574606467376, model__neurons1=105, model__neurons2=32, model__neurons3=68, model__neurons4=64; total time=  15.3s\n",
            "[CV] END batch_size=62, epochs=96, model__dropout1=0.44866077138528604, model__dropout2=0.26632843503178144, model__learning_rate=0.0001390574606467376, model__neurons1=105, model__neurons2=32, model__neurons3=68, model__neurons4=64; total time=  15.0s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END batch_size=8, epochs=105, model__dropout1=0.396513097747211, model__dropout2=0.20182170314561798, model__learning_rate=0.000544493887456265, model__neurons1=117, model__neurons2=62, model__neurons3=47, model__neurons4=88; total time=  37.8s\n",
            "[CV] END batch_size=8, epochs=105, model__dropout1=0.396513097747211, model__dropout2=0.20182170314561798, model__learning_rate=0.000544493887456265, model__neurons1=117, model__neurons2=62, model__neurons3=47, model__neurons4=88; total time=  40.7s\n",
            "[CV] END batch_size=8, epochs=105, model__dropout1=0.396513097747211, model__dropout2=0.20182170314561798, model__learning_rate=0.000544493887456265, model__neurons1=117, model__neurons2=62, model__neurons3=47, model__neurons4=88; total time=  38.5s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END batch_size=24, epochs=76, model__dropout1=0.29653280851662633, model__dropout2=0.26992664121876553, model__learning_rate=0.000767590147349823, model__neurons1=178, model__neurons2=45, model__neurons3=99, model__neurons4=16; total time=  16.3s\n",
            "[CV] END batch_size=24, epochs=76, model__dropout1=0.29653280851662633, model__dropout2=0.26992664121876553, model__learning_rate=0.000767590147349823, model__neurons1=178, model__neurons2=45, model__neurons3=99, model__neurons4=16; total time=  17.9s\n",
            "[CV] END batch_size=24, epochs=76, model__dropout1=0.29653280851662633, model__dropout2=0.26992664121876553, model__learning_rate=0.000767590147349823, model__neurons1=178, model__neurons2=45, model__neurons3=99, model__neurons4=16; total time=  17.5s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END batch_size=12, epochs=93, model__dropout1=0.39518819436313657, model__dropout2=0.22047667421718886, model__learning_rate=0.01, model__neurons1=64, model__neurons2=111, model__neurons3=84, model__neurons4=45; total time=  31.3s\n",
            "[CV] END batch_size=12, epochs=93, model__dropout1=0.39518819436313657, model__dropout2=0.22047667421718886, model__learning_rate=0.01, model__neurons1=64, model__neurons2=111, model__neurons3=84, model__neurons4=45; total time=  28.1s\n",
            "[CV] END batch_size=12, epochs=93, model__dropout1=0.39518819436313657, model__dropout2=0.22047667421718886, model__learning_rate=0.01, model__neurons1=64, model__neurons2=111, model__neurons3=84, model__neurons4=45; total time=  30.8s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END batch_size=51, epochs=67, model__dropout1=0.5, model__dropout2=0.19971740460214904, model__learning_rate=0.0011049088001254957, model__neurons1=165, model__neurons2=76, model__neurons3=106, model__neurons4=18; total time=  12.0s\n",
            "[CV] END batch_size=51, epochs=67, model__dropout1=0.5, model__dropout2=0.19971740460214904, model__learning_rate=0.0011049088001254957, model__neurons1=165, model__neurons2=76, model__neurons3=106, model__neurons4=18; total time=  12.8s\n",
            "[CV] END batch_size=51, epochs=67, model__dropout1=0.5, model__dropout2=0.19971740460214904, model__learning_rate=0.0011049088001254957, model__neurons1=165, model__neurons2=76, model__neurons3=106, model__neurons4=18; total time=  12.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END batch_size=47, epochs=110, model__dropout1=0.11697402560107992, model__dropout2=0.3402964164055061, model__learning_rate=0.01, model__neurons1=94, model__neurons2=32, model__neurons3=58, model__neurons4=35; total time=  16.7s\n",
            "[CV] END batch_size=47, epochs=110, model__dropout1=0.11697402560107992, model__dropout2=0.3402964164055061, model__learning_rate=0.01, model__neurons1=94, model__neurons2=32, model__neurons3=58, model__neurons4=35; total time=  18.5s\n",
            "[CV] END batch_size=47, epochs=110, model__dropout1=0.11697402560107992, model__dropout2=0.3402964164055061, model__learning_rate=0.01, model__neurons1=94, model__neurons2=32, model__neurons3=58, model__neurons4=35; total time=  14.9s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END batch_size=15, epochs=82, model__dropout1=0.437837363697527, model__dropout2=0.49129345722942663, model__learning_rate=0.0023753600223459584, model__neurons1=64, model__neurons2=44, model__neurons3=118, model__neurons4=16; total time=  19.3s\n",
            "[CV] END batch_size=15, epochs=82, model__dropout1=0.437837363697527, model__dropout2=0.49129345722942663, model__learning_rate=0.0023753600223459584, model__neurons1=64, model__neurons2=44, model__neurons3=118, model__neurons4=16; total time=  18.1s\n",
            "[CV] END batch_size=15, epochs=82, model__dropout1=0.437837363697527, model__dropout2=0.49129345722942663, model__learning_rate=0.0023753600223459584, model__neurons1=64, model__neurons2=44, model__neurons3=118, model__neurons4=16; total time=  20.7s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END batch_size=43, epochs=99, model__dropout1=0.3407692303130304, model__dropout2=0.3085534888822144, model__learning_rate=0.0016722287056141383, model__neurons1=159, model__neurons2=74, model__neurons3=115, model__neurons4=26; total time=  17.0s\n",
            "[CV] END batch_size=43, epochs=99, model__dropout1=0.3407692303130304, model__dropout2=0.3085534888822144, model__learning_rate=0.0016722287056141383, model__neurons1=159, model__neurons2=74, model__neurons3=115, model__neurons4=26; total time=  18.3s\n",
            "[CV] END batch_size=43, epochs=99, model__dropout1=0.3407692303130304, model__dropout2=0.3085534888822144, model__learning_rate=0.0016722287056141383, model__neurons1=159, model__neurons2=74, model__neurons3=115, model__neurons4=26; total time=  18.9s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END batch_size=55, epochs=104, model__dropout1=0.24400398152934077, model__dropout2=0.26064253249826796, model__learning_rate=0.0002609720407930833, model__neurons1=221, model__neurons2=103, model__neurons3=83, model__neurons4=96; total time=  18.4s\n",
            "[CV] END batch_size=55, epochs=104, model__dropout1=0.24400398152934077, model__dropout2=0.26064253249826796, model__learning_rate=0.0002609720407930833, model__neurons1=221, model__neurons2=103, model__neurons3=83, model__neurons4=96; total time=  19.7s\n",
            "[CV] END batch_size=55, epochs=104, model__dropout1=0.24400398152934077, model__dropout2=0.26064253249826796, model__learning_rate=0.0002609720407930833, model__neurons1=221, model__neurons2=103, model__neurons3=83, model__neurons4=96; total time=  19.4s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END batch_size=32, epochs=103, model__dropout1=0.2064723760226017, model__dropout2=0.35462156472298645, model__learning_rate=0.0004974387673987024, model__neurons1=196, model__neurons2=119, model__neurons3=118, model__neurons4=55; total time=  20.4s\n",
            "[CV] END batch_size=32, epochs=103, model__dropout1=0.2064723760226017, model__dropout2=0.35462156472298645, model__learning_rate=0.0004974387673987024, model__neurons1=196, model__neurons2=119, model__neurons3=118, model__neurons4=55; total time=  19.1s\n",
            "[CV] END batch_size=32, epochs=103, model__dropout1=0.2064723760226017, model__dropout2=0.35462156472298645, model__learning_rate=0.0004974387673987024, model__neurons1=196, model__neurons2=119, model__neurons3=118, model__neurons4=55; total time=  20.4s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END batch_size=64, epochs=86, model__dropout1=0.1847491550123622, model__dropout2=0.406405794781873, model__learning_rate=0.0004336608578945769, model__neurons1=223, model__neurons2=128, model__neurons3=32, model__neurons4=96; total time=  15.4s\n",
            "[CV] END batch_size=64, epochs=86, model__dropout1=0.1847491550123622, model__dropout2=0.406405794781873, model__learning_rate=0.0004336608578945769, model__neurons1=223, model__neurons2=128, model__neurons3=32, model__neurons4=96; total time=  15.3s\n",
            "[CV] END batch_size=64, epochs=86, model__dropout1=0.1847491550123622, model__dropout2=0.406405794781873, model__learning_rate=0.0004336608578945769, model__neurons1=223, model__neurons2=128, model__neurons3=32, model__neurons4=96; total time=  16.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END batch_size=52, epochs=46, model__dropout1=0.2695005899539936, model__dropout2=0.4410583324297497, model__learning_rate=0.0003345558682178352, model__neurons1=190, model__neurons2=128, model__neurons3=100, model__neurons4=17; total time=   8.9s\n",
            "[CV] END batch_size=52, epochs=46, model__dropout1=0.2695005899539936, model__dropout2=0.4410583324297497, model__learning_rate=0.0003345558682178352, model__neurons1=190, model__neurons2=128, model__neurons3=100, model__neurons4=17; total time=  10.9s\n",
            "[CV] END batch_size=52, epochs=46, model__dropout1=0.2695005899539936, model__dropout2=0.4410583324297497, model__learning_rate=0.0003345558682178352, model__neurons1=190, model__neurons2=128, model__neurons3=100, model__neurons4=17; total time=  10.7s\n",
            " Best Parameters Found:\n",
            "OrderedDict({'batch_size': 32, 'epochs': 103, 'model__dropout1': 0.2064723760226017, 'model__dropout2': 0.35462156472298645, 'model__learning_rate': 0.0004974387673987024, 'model__neurons1': 196, 'model__neurons2': 119, 'model__neurons3': 118, 'model__neurons4': 55})\n",
            "Best CV Accuracy: 0.8480511608171183\n"
          ]
        }
      ],
      "source": [
        "from scikeras.wrappers import KerasClassifier\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer\n",
        "\n",
        "# Wrapper (you can also tune epochs/batch_size via BayesSearchCV)\n",
        "clf = KerasClassifier(\n",
        "    model=build_model,\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Expanded search space for 4 dense layers\n",
        "search_space = {\n",
        "    'model__learning_rate': Real(1e-5, 1e-2, prior='log-uniform'),\n",
        "    'model__dropout1': Real(0.1, 0.5),\n",
        "    'model__dropout2': Real(0.1, 0.5),\n",
        "    'model__neurons1': Integer(64, 256),\n",
        "    'model__neurons2': Integer(32, 128),\n",
        "    'model__neurons3': Integer(32, 128),\n",
        "    'model__neurons4': Integer(16, 96),\n",
        "\n",
        "    # Also tune training dynamics\n",
        "    'batch_size': Integer(8, 64),\n",
        "    'epochs': Integer(40, 120),\n",
        "}\n",
        "\n",
        "opt = BayesSearchCV(\n",
        "    estimator=clf,\n",
        "    search_spaces=search_space,\n",
        "    n_iter=20,          # you can increase to 30–50 if time permits\n",
        "    scoring='accuracy',\n",
        "    cv=3,\n",
        "    n_jobs=1,           # keep 1 for Colab stability with TF\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "opt.fit(X_train, y_train_enc)\n",
        "\n",
        "print(\" Best Parameters Found:\")\n",
        "print(opt.best_params_)\n",
        "print(\"Best CV Accuracy:\", opt.best_score_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Pa1nQuW9aOXp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Set a global seed for reproducibility\n",
        "seed_value = 42\n",
        "tf.random.set_seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "random.seed(seed_value)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCRTr1dqPi-X"
      },
      "source": [
        "training final model using the best hyperparameters found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7bFek1-MHWJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
        "\n",
        "# Set seed for reproducibility\n",
        "seed_value = 42\n",
        "tf.random.set_seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "random.seed(seed_value)\n",
        "\n",
        "# Extract best hyperparameters\n",
        "best_params = opt.best_params_\n",
        "\n",
        "# Build final model\n",
        "final_model = build_model(\n",
        "    learning_rate=best_params['model__learning_rate'],\n",
        "    dropout1=best_params['model__dropout1'],\n",
        "    dropout2=best_params['model__dropout2'],\n",
        "    neurons1=best_params['model__neurons1'],\n",
        "    neurons2=best_params['model__neurons2'],\n",
        "    neurons3=best_params['model__neurons3'],\n",
        "    neurons4=best_params['model__neurons4']\n",
        ")\n",
        "\n",
        "# Add early stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=2,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "lr_sched = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=4,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train final model\n",
        "history = final_model.fit(\n",
        "    X_train, y_train_enc,\n",
        "    validation_data=(X_val, y_val_enc),\n",
        "    epochs=best_params['epochs'],\n",
        "    batch_size=best_params['batch_size'],\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLXpU0qiUoYa"
      },
      "outputs": [],
      "source": [
        "# Final evaluation on validation data\n",
        "val_loss, val_accuracy = final_model.evaluate(X_val, y_val_enc, verbose=0)\n",
        "print(f\"Final Validation Accuracy: {val_accuracy:.4f}\")\n",
        "print(f\"Final Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "# Evaluation on training data\n",
        "train_loss, train_accuracy = final_model.evaluate(X_train, y_train_enc, verbose=0)\n",
        "print(f\"Final Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Final Training Loss: {train_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evCpEvBQMPAm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy', marker='o')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy', marker='x')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss', marker='o')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss', marker='x')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ly6YRm6PtAH"
      },
      "source": [
        "test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQYF4jkKMkgg"
      },
      "outputs": [],
      "source": [
        "# Load test dataset\n",
        "test_path = '/content/drive/My Drive/test_data (31).xlsx'\n",
        "test_df = pd.read_excel(test_path)\n",
        "print(\"Test shape:\", test_df.shape)\n",
        "\n",
        "# Extract features and target\n",
        "X_test = test_df[feature_cols]\n",
        "y_test = test_df[target_col]\n",
        "y_test_enc = le.transform(y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFHWO5VePzEi"
      },
      "source": [
        "evaluate your trained model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd42N49VMnjS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report\n",
        ")\n",
        "\n",
        "# Predict probabilities\n",
        "y_test_pred_proba = final_model.predict(X_test)\n",
        "\n",
        "# Predicted class labels\n",
        "y_test_pred = np.argmax(y_test_pred_proba, axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCGtnQSYP4-G"
      },
      "source": [
        "classification metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQaXhvKoMp4H"
      },
      "outputs": [],
      "source": [
        "# Evaluate\n",
        "accuracy = accuracy_score(y_test_enc, y_test_pred)\n",
        "precision_macro = precision_score(y_test_enc, y_test_pred, average='macro')\n",
        "recall_macro = recall_score(y_test_enc, y_test_pred, average='macro')\n",
        "f1_macro = f1_score(y_test_enc, y_test_pred, average='macro')\n",
        "\n",
        "precision_weighted = precision_score(y_test_enc, y_test_pred, average='weighted')\n",
        "recall_weighted = recall_score(y_test_enc, y_test_pred, average='weighted')\n",
        "f1_weighted = f1_score(y_test_enc, y_test_pred, average='weighted')\n",
        "\n",
        "print(\"\\n Test Set Evaluation Metrics:\")\n",
        "print(f\"Accuracy:            {accuracy:.4f}\")\n",
        "print(f\"Macro Precision:     {precision_macro:.4f}\")\n",
        "print(f\"Macro Recall:        {recall_macro:.4f}\")\n",
        "print(f\"Macro F1 Score:      {f1_macro:.4f}\")\n",
        "print(f\"Weighted Precision:  {precision_weighted:.4f}\")\n",
        "print(f\"Weighted Recall:     {recall_weighted:.4f}\")\n",
        "print(f\"Weighted F1 Score:   {f1_weighted:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxFUeuRwUuPQ"
      },
      "outputs": [],
      "source": [
        "test_loss, test_accuracy = final_model.evaluate(X_test, y_test_enc, verbose=0)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCun5MwcsO8X"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make sure you've already predicted the test set\n",
        "# y_test_pred = np.argmax(pred_probs, axis=1)\n",
        "# y_test_enc = le.transform(y_test)\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_test_enc, y_test_pred)\n",
        "\n",
        "# Display the matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
        "\n",
        "# Plot it\n",
        "plt.figure(figsize=(6, 5))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.grid(False)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6wfExIDdN9h"
      },
      "outputs": [],
      "source": [
        "# After splitting your data into X_train, X_val, and X_test\n",
        "# Compute and save normalization stats for X_train\n",
        "np.save('/content/drive/MyDrive/train_feature_means.npy', X_train.mean().values)\n",
        "np.save('/content/drive/MyDrive/train_feature_stds.npy', X_train.std(ddof=0).values)\n",
        "\n",
        "# Save the label classes\n",
        "np.save('/content/drive/MyDrive/grade_label_classes.npy', le.classes_)\n",
        "\n",
        "# Save the trained model\n",
        "final_model.save('/content/optimized_final_grade_model1.h5')\n",
        "\n",
        "# Move model to Google Drive\n",
        "!cp /content/optimized_final_grade_model.h5 /content/drive/MyDrive/\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+FFJH1hhIhwUAfRWbWQaJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}